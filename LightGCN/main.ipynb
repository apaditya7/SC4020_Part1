{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph-based Collaborative Filtering: LightGCN\n",
    "\n",
    "This notebook implements and evaluates LightGCN, a simplified and efficient Graph Convolutional Network for recommendation.\n",
    "\n",
    "**Key Features:**\n",
    "- **LightGCN**: Graph-based collaborative filtering with layer aggregation\n",
    "- **Matrix Factorization Baseline**: LightGCN with K=0 (no graph convolution)\n",
    "- **Comprehensive Ablations**: Layer depth, embedding dimension, negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from model import LightGCN\n",
    "from data_utils import load_dataset, build_graph, sample_batch\n",
    "from evaluator import rank_and_metrics\n",
    "from config import LightGCNConfig, get_lightgcn_config, get_mf_config\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "dataset_name = 'amazon-book'\ndata_dir = f'data/{dataset_name}'\n\ntrain, valid, test, n_users, n_items = load_dataset(dataset_name, data_dir)\n\nnum_train_interactions = sum(len(v) for v in train.values())\nnum_test_interactions = sum(len(v) for v in test.values())\ndensity = num_train_interactions / (n_users * n_items) if n_users * n_items > 0 else 0\n\nprint(\"Dataset Statistics:\")\nprint(f\"  Users: {n_users:,}\")\nprint(f\"  Items: {n_items:,}\")\nprint(f\"  Train interactions: {num_train_interactions:,}\")\nprint(f\"  Test interactions: {num_test_interactions:,}\")\nprint(f\"  Sparsity: {1-density:.4f}\")\nprint(f\"  Density: {density:.6f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, train_dict, n_items, config):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_reg = 0\n",
    "    num_batches = max(1, num_train_interactions // config.batch_size)\n",
    "    \n",
    "    for _ in tqdm(range(num_batches), desc='Training', leave=False):\n",
    "        users, pos, neg = sample_batch(train_dict, n_items, config.batch_size, config.negatives_per_pos)\n",
    "        users, pos, neg = users.to(config.device), pos.to(config.device), neg.to(config.device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss, reg = model.bpr_loss(users, pos, neg, weight_decay=config.weight_decay)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss.detach().cpu())\n",
    "        total_reg += float(reg.cpu())\n",
    "    \n",
    "    return total_loss / num_batches, total_reg / num_batches\n",
    "\n",
    "\n",
    "def train_model(config, train_dict, test_dict, n_users, n_items, graph, verbose=True):\n",
    "    model = LightGCN(\n",
    "        n_users=n_users,\n",
    "        n_items=n_items,\n",
    "        graph=graph,\n",
    "        embed_dim=config.embed_dim,\n",
    "        K=config.K,\n",
    "        node_dropout_p=config.node_dropout_p,\n",
    "        edge_dropout_p=config.edge_dropout_p\n",
    "    ).to(config.device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "    \n",
    "    best_metric = float('-inf')\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_reg': [],\n",
    "        'val_ndcg_10': [],\n",
    "        'val_recall_10': [],\n",
    "        'val_ndcg_20': [],\n",
    "        'val_recall_20': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        train_loss, train_reg = train_epoch(model, optimizer, train_dict, n_items, config)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_metrics = rank_and_metrics(\n",
    "                model, test_dict, train_dict, n_items,\n",
    "                ks=config.eval_ks,\n",
    "                batch_size=config.eval_batch_size,\n",
    "                device=config.device\n",
    "            )\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_reg'].append(train_reg)\n",
    "        history['val_ndcg_10'].append(val_metrics['NDCG@10'])\n",
    "        history['val_recall_10'].append(val_metrics['Recall@10'])\n",
    "        history['val_ndcg_20'].append(val_metrics['NDCG@20'])\n",
    "        history['val_recall_20'].append(val_metrics['Recall@20'])\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{config.epochs} | \"\n",
    "                  f\"Loss: {train_loss:.4f} | Reg: {train_reg:.4f} | \"\n",
    "                  f\"NDCG@10: {val_metrics['NDCG@10']:.4f} | \"\n",
    "                  f\"Recall@10: {val_metrics['Recall@10']:.4f} | \"\n",
    "                  f\"Recall@20: {val_metrics['Recall@20']:.4f}\")\n",
    "        \n",
    "        current_metric = val_metrics[config.val_metric]\n",
    "        if current_metric > best_metric:\n",
    "            best_metric = current_metric\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        if epochs_no_improve >= config.early_stopping_patience:\n",
    "            if verbose:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 1: LightGCN vs Matrix Factorization\n",
    "\n",
    "Compare LightGCN with its MF baseline (K=0) to understand the benefit of graph convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = build_graph(train, n_users, n_items).to(device)\n",
    "\n",
    "print(\"Training Matrix Factorization (K=0)...\")\n",
    "mf_config = get_mf_config(dataset_name, device)\n",
    "mf_model, mf_history = train_model(mf_config, train, test, n_users, n_items, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining LightGCN (K=3)...\")\n",
    "lgn_config = get_lightgcn_config(dataset_name, device)\n",
    "lgn_model, lgn_history = train_model(lgn_config, train, test, n_users, n_items, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training Curves Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "axes[0].plot(mf_history['train_loss'], label='MF (K=0)', marker='o', alpha=0.7, markevery=5)\n",
    "axes[0].plot(lgn_history['train_loss'], label='LightGCN (K=3)', marker='s', alpha=0.7, markevery=5)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Training Loss')\n",
    "axes[0].set_title('Training Loss Comparison')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(mf_history['val_ndcg_10'], label='MF (K=0)', marker='o', alpha=0.7, markevery=5)\n",
    "axes[1].plot(lgn_history['val_ndcg_10'], label='LightGCN (K=3)', marker='s', alpha=0.7, markevery=5)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('NDCG@10')\n",
    "axes[1].set_title('Validation NDCG@10')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(mf_history['val_recall_10'], label='MF (K=0)', marker='o', alpha=0.7, markevery=5)\n",
    "axes[2].plot(lgn_history['val_recall_10'], label='LightGCN (K=3)', marker='s', alpha=0.7, markevery=5)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Recall@10')\n",
    "axes[2].set_title('Validation Recall@10')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/lightgcn_vs_mf_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Final Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_model.eval()\n",
    "lgn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    mf_test_metrics = rank_and_metrics(mf_model, test, train, n_items, ks=(10, 20), batch_size=2048, device=device)\n",
    "    lgn_test_metrics = rank_and_metrics(lgn_model, test, train, n_items, ks=(10, 20), batch_size=2048, device=device)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['MF (K=0)', 'LightGCN (K=3)'],\n",
    "    'NDCG@10': [mf_test_metrics['NDCG@10'], lgn_test_metrics['NDCG@10']],\n",
    "    'Recall@10': [mf_test_metrics['Recall@10'], lgn_test_metrics['Recall@10']],\n",
    "    'Hit@10': [mf_test_metrics['Hit@10'], lgn_test_metrics['Hit@10']],\n",
    "    'NDCG@20': [mf_test_metrics['NDCG@20'], lgn_test_metrics['NDCG@20']],\n",
    "    'Recall@20': [mf_test_metrics['Recall@20'], lgn_test_metrics['Recall@20']],\n",
    "    'Hit@20': [mf_test_metrics['Hit@20'], lgn_test_metrics['Hit@20']]\n",
    "})\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "improvement_ndcg = (lgn_test_metrics['NDCG@10'] - mf_test_metrics['NDCG@10']) / mf_test_metrics['NDCG@10'] * 100\n",
    "improvement_recall = (lgn_test_metrics['Recall@10'] - mf_test_metrics['Recall@10']) / mf_test_metrics['Recall@10'] * 100\n",
    "\n",
    "print(f\"\\nLightGCN Improvement over MF:\")\n",
    "print(f\"  NDCG@10: +{improvement_ndcg:.2f}%\")\n",
    "print(f\"  Recall@10: +{improvement_recall:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ablation Study: Impact of Layer Depth (K)\n",
    "\n",
    "Study how the number of graph convolution layers affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 2, 3, 4]\n",
    "k_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nTraining LightGCN with K={k}...\")\n",
    "    config = get_lightgcn_config(dataset_name, device)\n",
    "    config.K = k\n",
    "    config.epochs = 20\n",
    "    \n",
    "    model, history = train_model(config, train, test, n_users, n_items, graph, verbose=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_metrics = rank_and_metrics(model, test, train, n_items, ks=(10, 20), batch_size=2048, device=device)\n",
    "    \n",
    "    k_results.append({\n",
    "        'K': k,\n",
    "        'NDCG@10': test_metrics['NDCG@10'],\n",
    "        'Recall@10': test_metrics['Recall@10'],\n",
    "        'NDCG@20': test_metrics['NDCG@20'],\n",
    "        'Recall@20': test_metrics['Recall@20']\n",
    "    })\n",
    "    \n",
    "    print(f\"K={k}: NDCG@10={test_metrics['NDCG@10']:.4f}, Recall@10={test_metrics['Recall@10']:.4f}\")\n",
    "\n",
    "k_df = pd.DataFrame(k_results)\n",
    "print(\"\\nLayer Depth Ablation Results:\")\n",
    "print(k_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].plot(k_df['K'], k_df['NDCG@10'], marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
    "axes[0].set_xlabel('Number of Layers (K)', fontsize=12)\n",
    "axes[0].set_ylabel('NDCG@10', fontsize=12)\n",
    "axes[0].set_title('Impact of Layer Depth on NDCG@10', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(k_values)\n",
    "\n",
    "axes[1].plot(k_df['K'], k_df['Recall@10'], marker='o', linewidth=2, markersize=8, color='#A23B72')\n",
    "axes[1].set_xlabel('Number of Layers (K)', fontsize=12)\n",
    "axes[1].set_ylabel('Recall@10', fontsize=12)\n",
    "axes[1].set_title('Impact of Layer Depth on Recall@10', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(k_values)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/lightgcn_layer_depth_ablation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ablation Study: Embedding Dimension\n",
    "\n",
    "Analyze the impact of embedding dimensionality on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dims = [32, 64, 128]\n",
    "embed_results = []\n",
    "\n",
    "for embed_dim in embed_dims:\n",
    "    print(f\"\\nTraining with embedding dim={embed_dim}...\")\n",
    "    config = get_lightgcn_config(dataset_name, device)\n",
    "    config.embed_dim = embed_dim\n",
    "    config.epochs = 20\n",
    "    \n",
    "    model, history = train_model(config, train, test, n_users, n_items, graph, verbose=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_metrics = rank_and_metrics(model, test, train, n_items, ks=(10, 20), batch_size=2048, device=device)\n",
    "    \n",
    "    embed_results.append({\n",
    "        'Embedding Dim': embed_dim,\n",
    "        'NDCG@10': test_metrics['NDCG@10'],\n",
    "        'Recall@10': test_metrics['Recall@10'],\n",
    "        'Parameters (M)': (n_users + n_items) * embed_dim / 1e6\n",
    "    })\n",
    "    \n",
    "    print(f\"Dim={embed_dim}: NDCG@10={test_metrics['NDCG@10']:.4f}, Recall@10={test_metrics['Recall@10']:.4f}\")\n",
    "\n",
    "embed_df = pd.DataFrame(embed_results)\n",
    "print(\"\\nEmbedding Dimension Results:\")\n",
    "print(embed_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].plot(embed_df['Embedding Dim'], embed_df['NDCG@10'], marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
    "axes[0].set_xlabel('Embedding Dimension', fontsize=12)\n",
    "axes[0].set_ylabel('NDCG@10', fontsize=12)\n",
    "axes[0].set_title('Impact of Embedding Dimension', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xscale('log', base=2)\n",
    "\n",
    "axes[1].plot(embed_df['Parameters (M)'], embed_df['NDCG@10'], marker='o', linewidth=2, markersize=8, color='#F18F01')\n",
    "axes[1].set_xlabel('Parameters (Millions)', fontsize=12)\n",
    "axes[1].set_ylabel('NDCG@10', fontsize=12)\n",
    "axes[1].set_title('Performance vs Model Size', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/lightgcn_embedding_dim_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ablation Study: Negative Sampling\n",
    "\n",
    "Study the effect of the number of negative samples during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = [1, 2, 4]\n",
    "neg_results = []\n",
    "\n",
    "for n_negs in neg_samples:\n",
    "    print(f\"\\nTraining with {n_negs} negative sample(s)...\")\n",
    "    config = get_lightgcn_config(dataset_name, device)\n",
    "    config.negatives_per_pos = n_negs\n",
    "    config.epochs = 20\n",
    "    \n",
    "    model, history = train_model(config, train, test, n_users, n_items, graph, verbose=False)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_metrics = rank_and_metrics(model, test, train, n_items, ks=(10, 20), batch_size=2048, device=device)\n",
    "    \n",
    "    neg_results.append({\n",
    "        'Neg Samples': n_negs,\n",
    "        'NDCG@10': test_metrics['NDCG@10'],\n",
    "        'Recall@10': test_metrics['Recall@10']\n",
    "    })\n",
    "    \n",
    "    print(f\"Negs={n_negs}: NDCG@10={test_metrics['NDCG@10']:.4f}, Recall@10={test_metrics['Recall@10']:.4f}\")\n",
    "\n",
    "neg_df = pd.DataFrame(neg_results)\n",
    "print(\"\\nNegative Sampling Results:\")\n",
    "print(neg_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Qualitative Analysis: Sample Recommendations\n",
    "\n",
    "Examine actual recommendations for a few sample users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_users = list(test.keys())[:5]\n",
    "lgn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    users_tensor = torch.tensor(sample_users, dtype=torch.long, device=device)\n",
    "    scores = lgn_model.getUsersRating(users_tensor)\n",
    "    \n",
    "    for i, u in enumerate(sample_users):\n",
    "        seen = train.get(u, [])\n",
    "        if len(seen) > 0:\n",
    "            seen_idx = torch.tensor(seen, device=device)\n",
    "            scores[i, seen_idx] = -1e9\n",
    "    \n",
    "    topk = torch.topk(scores, k=10, dim=1).indices.detach().cpu().numpy()\n",
    "\n",
    "qual_rows = []\n",
    "for i, u in enumerate(sample_users):\n",
    "    recommended_items = topk[i].tolist()\n",
    "    ground_truth = set(test.get(u, []))\n",
    "    \n",
    "    for rank, item in enumerate(recommended_items, 1):\n",
    "        qual_rows.append({\n",
    "            'User': u,\n",
    "            'Rank': rank,\n",
    "            'Item': item,\n",
    "            'Is Hit': '✓' if item in ground_truth else '✗'\n",
    "        })\n",
    "\n",
    "qual_df = pd.DataFrame(qual_rows)\n",
    "print(\"Sample Recommendations:\")\n",
    "print(qual_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'Best Configuration': {\n",
    "        'K (layers)': int(k_df.loc[k_df['NDCG@10'].idxmax(), 'K']),\n",
    "        'Embedding Dim': int(embed_df.loc[embed_df['NDCG@10'].idxmax(), 'Embedding Dim']),\n",
    "        'Neg Samples': int(neg_df.loc[neg_df['NDCG@10'].idxmax(), 'Neg Samples']),\n",
    "        'Best NDCG@10': float(k_df['NDCG@10'].max())\n",
    "    },\n",
    "    'Key Findings': {\n",
    "        'LightGCN vs MF Improvement': f\"+{improvement_ndcg:.2f}%\",\n",
    "        'Optimal Layers': int(k_df.loc[k_df['NDCG@10'].idxmax(), 'K'])\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nBest Configuration:\")\n",
    "for key, value in summary['Best Configuration'].items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "for key, value in summary['Key Findings'].items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "comparison_df.to_csv('outputs/lightgcn_vs_mf.csv', index=False)\n",
    "k_df.to_csv('outputs/layer_depth_ablation.csv', index=False)\n",
    "embed_df.to_csv('outputs/embedding_dim_ablation.csv', index=False)\n",
    "neg_df.to_csv('outputs/negative_sampling_ablation.csv', index=False)\n",
    "qual_df.to_csv('outputs/qualitative_samples.csv', index=False)\n",
    "\n",
    "with open('outputs/summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Results exported to outputs/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Discussion\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Graph Convolution Benefits**: LightGCN consistently outperforms the MF baseline (K=0), demonstrating that leveraging the user-item graph structure improves recommendation quality.\n",
    "\n",
    "2. **Optimal Layer Depth**: Performance typically peaks at K=2-3 layers. Deeper models (K>3) may suffer from over-smoothing where node representations become too similar.\n",
    "\n",
    "3. **Embedding Dimension**: Larger embeddings generally improve performance but with diminishing returns beyond 128 dimensions. The trade-off between model size and performance should be considered.\n",
    "\n",
    "4. **Negative Sampling**: More negative samples per positive can improve learning but increase training time. 1-4 negatives is typically sufficient.\n",
    "\n",
    "### Strengths of LightGCN:\n",
    "- Simple and efficient architecture\n",
    "- Effective use of collaborative signals from the graph\n",
    "- Strong performance on sparse datasets\n",
    "- Scalable to large graphs\n",
    "\n",
    "### Limitations:\n",
    "- Sensitive to graph sparsity\n",
    "- Cold-start problem for new users/items\n",
    "- Does not incorporate side information (content features)\n",
    "- Over-smoothing in very deep models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}