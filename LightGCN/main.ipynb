{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGCN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from model import LightGCN\n",
    "from data_utils import load_dataset, build_graph, sample_batch\n",
    "from evaluator import rank_and_metrics\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED);\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "CFG = dict(\n",
    "    dataset='yelp2018',\n",
    "    data_dir='data/yelp2018',\n",
    "    seed=42, device=device,\n",
    "    epochs=10, batch_size=4096,\n",
    "    embed_dim=64, lr=1e-3, weight_decay=1e-4,\n",
    "    negatives_per_pos=1,\n",
    "    node_dropout_p=0.0, edge_dropout_p=0.0,\n",
    "    eval_ks=(10, 20),\n",
    ")\n",
    "\n",
    "def apply_method_cfg(cfg, method):\n",
    "    cfg = cfg.copy()\n",
    "    if method == 'mf_like':\n",
    "        cfg['K'] = 0\n",
    "    return cfg\n",
    "\n",
    "def resolve_data_dir(cfg):\n",
    "    dd = cfg['data_dir']\n",
    "    if os.path.exists(dd):\n",
    "        return dd\n",
    "    alt = os.path.join('LightGCN-PyTorch', 'data', cfg['dataset'])\n",
    "    if os.path.exists(alt):\n",
    "        return alt\n",
    "    raise FileNotFoundError(f'Dataset folder not found: {dd} or {alt}')\n",
    "\n",
    "CFGm = apply_method_cfg(CFG, METHOD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data loading & graph build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = resolve_data_dir(CFGm)\n",
    "train, valid, test, n_users, n_items = load_dataset(CFGm['dataset'], data_dir)\n",
    "\n",
    "graph = build_graph(train, n_users, n_items).to(device)\n",
    "num_inter = sum(len(v) for v in train.values())\n",
    "density = num_inter / (n_users * n_items) if n_users*n_items>0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model (single class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(\n",
    "    n_users=n_users, n_items=n_items, graph=graph,\n",
    "    embed_dim=CFGm['embed_dim'], K=CFGm['K'],\n",
    "    node_dropout_p=CFGm['node_dropout_p'], edge_dropout_p=CFGm['edge_dropout_p']\n",
    ").to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CFGm['lr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Training loop (BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(*tensors):\n",
    "    return [t.to(device) for t in tensors]\n",
    "\n",
    "history = []\n",
    "epochs = CFGm['epochs']\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    users, pos, neg = sample_batch(train, n_items, CFGm['batch_size'], CFGm['negatives_per_pos'])\n",
    "    users, pos, neg = to_device(users, pos, neg)\n",
    "    optimizer.zero_grad()\n",
    "    loss, reg = model.bpr_loss(users, pos, neg, weight_decay=CFGm['weight_decay'])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    history.append({'epoch': epoch, 'loss': float(loss.detach().cpu()), 'reg': float(reg.cpu())})\n",
    "    if epoch % max(1, epochs//5) == 0 or epoch == 1:\n",
    "\n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "metrics = rank_and_metrics(model, test, train, n_items, ks=CFGm['eval_ks'], batch_size=2048, device=device)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Ablations (K, dropout, weight decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def run_one(cfg, method):\n",
    "    cfgm = apply_method_cfg(cfg, method)\n",
    "    dd = resolve_data_dir(cfgm)\n",
    "    tr, va, te, U, I = load_dataset(cfgm['dataset'], dd)\n",
    "    g = build_graph(tr, U, I).to(device)\n",
    "    m = LightGCN(U, I, g, cfgm['embed_dim'], cfgm['K'], cfgm['node_dropout_p'], cfgm['edge_dropout_p']).to(device)\n",
    "    opt = optim.Adam(m.parameters(), lr=cfgm['lr'])\n",
    "    for ep in range(cfgm['epochs']):\n",
    "        m.train()\n",
    "        u, p, n = sample_batch(tr, I, cfgm['batch_size'], cfgm['negatives_per_pos'])\n",
    "        u, p, n = u.to(device), p.to(device), n.to(device)\n",
    "        opt.zero_grad()\n",
    "        loss, _ = m.bpr_loss(u, p, n, weight_decay=cfgm['weight_decay'])\n",
    "        loss.backward(); opt.step()\n",
    "    m.eval()\n",
    "    return rank_and_metrics(m, te, tr, I, ks=cfgm['eval_ks'], batch_size=2048, device=device)\n",
    "\n",
    "grid = {\n",
    "    'K': [0, 1, 2, 3],\n",
    "    'edge_dropout_p': [0.0, 0.2],\n",
    "    'node_dropout_p': [0.0, 0.2],\n",
    "    'weight_decay': [0.0, 1e-4, 1e-3],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Two datasets run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Plots & qualitative cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(); plt.plot(hist_df['epoch'], hist_df['loss']); plt.title('Train Loss'); plt.xlabel('epoch'); plt.ylabel('loss'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Results tables (for report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Export for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('outputs', exist_ok=True)\n",
    "hist_df.to_csv('outputs/train_history.csv', index=False)\n",
    "with open('outputs/summary.txt', 'w') as f:\n",
    "    f.write(json.dumps(dict(config=CFGm, metrics=metrics), indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}